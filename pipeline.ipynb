{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:09:57.099843Z",
     "start_time": "2025-05-30T19:09:53.885143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from ext.DeepLSD.deeplsd.models.deeplsd_inference import DeepLSD\n",
    "from ext.DeepLSD.deeplsd.geometry.viz_2d import plot_images, plot_lines\n",
    "import pyprogressivex\n",
    "from random import randint\n",
    "\n",
    "from yud import YUDVP\n",
    "from matplotlib.patches import Patch\n",
    "from ext.PerspectiveFields.perspective2d import PerspectiveFields\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "from ext.GeoCalib.geocalib.extractor import GeoCalib\n"
   ],
   "id": "7e012b4bc916cfda",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tab/Desktop/EPFL/MA2/CompPhotoProject/cs413-project/.venv/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:09:57.967318Z",
     "start_time": "2025-05-30T19:09:57.958994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytlsd import lsd\n",
    "\n",
    "def get_line_segments_deepLSD(img, model='default', show_detected_lines=False):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    #device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device('cpu')\n",
    "    conf = {\n",
    "        'detect_lines': True,  # Whether to detect lines or only DF/AF\n",
    "        'line_detection_params': {\n",
    "            'merge': True,  # Whether to merge close-by lines\n",
    "            'filtering': 'strict',  # Whether to filter out lines based on the DF/AF. Use 'strict' to get an even stricter filtering\n",
    "            'grad_thresh': 3,\n",
    "            'grad_nfa': True,  # If True, use the image gradient and the NFA score of LSD to further threshold lines. We recommand using it for easy images, but to turn it off for challenging images (e.g. night, foggy, blurry images)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Load the model\n",
    "    if model == 'default':\n",
    "        ckpt = \"ext/DeepLSD/weights/deeplsd_md.tar\"\n",
    "    elif model == 'wireframe':\n",
    "        ckpt = \"ext/DeepLSD/weights/deeplsd_wireframe.tar\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name. Use 'default' or 'wireframe'.\")\n",
    "    ckpt = torch.load(str(ckpt), map_location='cpu', weights_only=False)\n",
    "    net = DeepLSD(conf)\n",
    "    net.load_state_dict(ckpt['model'])\n",
    "    net = net.to(device).eval()\n",
    "\n",
    "    tensor = torch.tensor(gray_img, dtype=torch.float, device=device)[None, None] / 255.\n",
    "\n",
    "    inputs = {'image': tensor}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = net(inputs)\n",
    "        pred_lines = out['lines'][0]\n",
    "\n",
    "    if show_detected_lines:\n",
    "        plot_images([img], ['DeepLSD lines'], cmaps='gray')\n",
    "        plot_lines([pred_lines], indices=range(1))\n",
    "        plt.show()\n",
    "\n",
    "    # Transform the detected lines to the format of LSD\n",
    "    detected_linesegments = np.zeros((pred_lines.shape[0], 5))\n",
    "    for i in range(pred_lines.shape[0]):\n",
    "        pt1_x = pred_lines[i, 0, 0]\n",
    "        pt1_y = pred_lines[i, 0, 1]\n",
    "        pt2_x = pred_lines[i, 1, 0]\n",
    "        pt2_y = pred_lines[i, 1, 1]\n",
    "        pt1 = np.array([pt1_x, pt1_y])\n",
    "        pt2 = np.array([pt2_x, pt2_y])\n",
    "        dist = np.linalg.norm(pt1 - pt2)\n",
    "        detected_linesegments[i, :] = [pt1_x, pt1_y, pt2_x, pt2_y, dist]\n",
    "    detected_linesegments[:, 4] /= np.sum(detected_linesegments[:, 4])\n",
    "\n",
    "    del inputs\n",
    "    del pred_lines\n",
    "    del out\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if show_detected_lines:\n",
    "        # Save the image with detected lines to default folder\n",
    "        path = 'data/DeepLSD/linesegments'\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        line_img = img.copy()\n",
    "\n",
    "        for i in range(detected_linesegments.shape[0]):\n",
    "            # Convert the line to its implicit form\n",
    "            pt1 = np.array([detected_linesegments[i, 0], detected_linesegments[i, 1]])\n",
    "            pt2 = np.array([detected_linesegments[i, 2], detected_linesegments[i, 3]])\n",
    "            v = pt2 - pt1\n",
    "            line_length = np.linalg.norm(v)\n",
    "\n",
    "            if line_length < 0:\n",
    "                continue\n",
    "\n",
    "            # Draw the line\n",
    "            pt1i = (int(detected_linesegments[i, 0]), int(detected_linesegments[i, 1]))\n",
    "            pt2i = (int(detected_linesegments[i, 2]), int(detected_linesegments[i, 3]))\n",
    "            width = 3 # detected_linesegments[i, 4]\n",
    "            cv2.line(line_img, pt1i, pt2i, (255, 255, 255), int(np.ceil(width / 2)))\n",
    "\n",
    "\n",
    "        full_save_path = os.path.join(path, 'detected_linesegments.png')\n",
    "        cv2.imwrite(full_save_path, line_img)\n",
    "\n",
    "    return detected_linesegments\n",
    "\n",
    "def get_line_segments_LSD(img, show_detected_lines=False):\n",
    "\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    pred_lines = lsd(gray_img, density_th=0.0)\n",
    "\n",
    "    if show_detected_lines:\n",
    "        length_threshold = 0\n",
    "        linesegments = []\n",
    "        lengths = []\n",
    "\n",
    "        #Show image\n",
    "        line_img = img.copy()\n",
    "        for i in range(pred_lines.shape[0]):\n",
    "            # Convert the line to its implicit form\n",
    "            pt1 = np.array([pred_lines[i, 0], pred_lines[i, 1]])\n",
    "            pt2 = np.array([pred_lines[i, 2], pred_lines[i, 3]])\n",
    "            v = pt2 - pt1\n",
    "            line_length = np.linalg.norm(v)\n",
    "\n",
    "            if line_length < length_threshold:\n",
    "                continue\n",
    "\n",
    "            lengths.append(line_length)\n",
    "            linesegments.append(pred_lines[i, :])\n",
    "\n",
    "            # Draw the line\n",
    "            pt1i = (int(pred_lines[i, 0]), int(pred_lines[i, 1]))\n",
    "            pt2i = (int(pred_lines[i, 2]), int(pred_lines[i, 3]))\n",
    "            width = 3 # detected_linesegments[i, 4]\n",
    "            cv2.line(line_img, pt1i, pt2i, (0, 0, 255), int(np.ceil(width / 2)))\n",
    "        plt.imshow(line_img)\n",
    "\n",
    "    # Transform the detected lines to the format of LSD\n",
    "    detected_linesegments = np.zeros((pred_lines.shape[0], 5))\n",
    "    for i in range(pred_lines.shape[0]):\n",
    "        pt1_x = pred_lines[i, 0]\n",
    "        pt1_y = pred_lines[i, 1]\n",
    "        pt2_x = pred_lines[i, 2]\n",
    "        pt2_y = pred_lines[i, 3]\n",
    "        pt1 = np.array([pt1_x, pt1_y])\n",
    "        pt2 = np.array([pt2_x, pt2_y])\n",
    "        dist = np.linalg.norm(pt1 - pt2)\n",
    "        detected_linesegments[i, :] = [pt1_x, pt1_y, pt2_x, pt2_y, dist]\n",
    "    detected_linesegments[:, 4] /= np.sum(detected_linesegments[:, 4])\n",
    "    # Convert to numpy array\n",
    "    detected_linesegments = np.array(detected_linesegments)\n",
    "    return detected_linesegments"
   ],
   "id": "e883565f881e77df",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:09:58.632478Z",
     "start_time": "2025-05-30T19:09:58.612285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_vanishing_points(img, linesegments, threshold=0.1, minimum_point_number=2, maximum_model_number=-1):\n",
    "\n",
    "    def verify_pyprogressivex(img, lines, weights, threshold = 2.0):\n",
    "        vanishing_points, labeling = pyprogressivex.findVanishingPoints(\n",
    "            np.ascontiguousarray(lines),\n",
    "            np.ascontiguousarray(weights),\n",
    "            img.shape[1], img.shape[0],\n",
    "            threshold = threshold,\n",
    "            conf = 0.99,\n",
    "            spatial_coherence_weight = 0.0,\n",
    "            neighborhood_ball_radius = 1.0,\n",
    "            maximum_tanimoto_similarity = 1.0,\n",
    "            max_iters = 1_000_000,\n",
    "            minimum_point_number = minimum_point_number,\n",
    "            maximum_model_number = maximum_model_number,\n",
    "            sampler_id = 0,\n",
    "            scoring_exponent = 1.0,\n",
    "            do_logging = False)\n",
    "        return vanishing_points, labeling\n",
    "\n",
    "    linesegments[:,4] /= np.sum(linesegments[:,4])\n",
    "    vanishing_points, labeling = verify_pyprogressivex(img, linesegments[:,0:4], linesegments, threshold=threshold)\n",
    "    predicted_vanishing_points = []\n",
    "\n",
    "    model_number = int(vanishing_points.size / 3)\n",
    "\n",
    "    for idx in range(model_number):\n",
    "        vp = vanishing_points[idx]\n",
    "\n",
    "        if abs(vp[2]) < 1e-10:\n",
    "            continue\n",
    "\n",
    "        vp /= vp[2]\n",
    "        vp = (int(vp[0]), int(vp[1]))\n",
    "\n",
    "        predicted_vanishing_points.append(vp)\n",
    "\n",
    "    return np.array(predicted_vanishing_points), labeling\n",
    "\n",
    "def display_vanishing_points(img, linesegments, vanishing_points, labeling, display_outliers=False, is_manhattan=None):\n",
    "    line_img = img.copy()\n",
    "    model_number = vanishing_points.shape[0]\n",
    "\n",
    "    legend_patches = []\n",
    "\n",
    "    colours = [\n",
    "        [255, 0, 0],  # Red\n",
    "        [0, 255, 0],  # Green\n",
    "        [0, 0, 255],  # Blue\n",
    "        [255, 255, 0],  # Yellow\n",
    "        [0, 255, 255],  # Cyan\n",
    "        [255, 0, 255],  # Magenta\n",
    "        [128, 0, 0],  # Dark Red\n",
    "        [0, 128, 0],  # Dark Green\n",
    "        [0, 0, 128],  # Dark Blue\n",
    "        [255, 165, 0],  # Orange\n",
    "        [255, 192, 203],  # Pink\n",
    "        [75, 0, 130],  # Indigo\n",
    "        [0, 128, 128],  # Teal\n",
    "        [128, 0, 128],  # Purple\n",
    "    ]\n",
    "    num_of_colours = len(colours)\n",
    "\n",
    "    if display_outliers:\n",
    "        idx = model_number\n",
    "        indices = [i for i, e in enumerate(labeling) if e == idx]\n",
    "        color = (255, 255, 255)\n",
    "\n",
    "        # OpenCV uses BGR, matplotlib uses RGB\n",
    "        color_rgb = tuple([c / 255. for c in color[::-1]])\n",
    "        legend_label = f\"Outliers: {len(indices)} lines\"\n",
    "        legend_patches.append(Patch(color=color_rgb, label=legend_label))\n",
    "        print(f\"Drawing the lines assigned to the outliers. Label: {idx}\")\n",
    "        print(f\"# inliers = {len(indices)}\")\n",
    "        for i in indices:\n",
    "            pt1i = (int(linesegments[i, 0]), int(linesegments[i, 1]))\n",
    "            pt2i = (int(linesegments[i, 2]), int(linesegments[i, 3]))\n",
    "            width = 6  # static width; could be dynamic\n",
    "            cv2.line(line_img, pt1i, pt2i, color, int(np.ceil(width / 2)))\n",
    "\n",
    "    for idx in range(model_number):\n",
    "        indices = [i for i, e in enumerate(labeling) if e == idx]\n",
    "        if idx < num_of_colours:\n",
    "            color = colours[idx]\n",
    "        else:\n",
    "            color = (randint(0, 255), randint(0, 255), randint(0, 255))\n",
    "\n",
    "        # OpenCV uses BGR, matplotlib uses RGB\n",
    "        color_rgb = tuple([c / 255. for c in color[::-1]])\n",
    "        print('vanishing_points[idx]:', vanishing_points[idx], type(vanishing_points[idx]))\n",
    "        legend_label = f\"VP {idx}: {tuple(map(int, vanishing_points[idx]))}\"\n",
    "\n",
    "        legend_patches.append(Patch(color=color_rgb, label=legend_label))\n",
    "\n",
    "        vp = tuple(map(int, vanishing_points[idx]))\n",
    "\n",
    "        print(f\"Drawing the lines assigned to the {int(idx + 1)}-th vanishing point.\")\n",
    "        print(f\"# inliers = {len(indices)}\")\n",
    "\n",
    "        for i in indices:\n",
    "            pt1i = (int(linesegments[i, 0]), int(linesegments[i, 1]))\n",
    "            pt2i = (int(linesegments[i, 2]), int(linesegments[i, 3]))\n",
    "            width = 3  # static width; could be dynamic\n",
    "            cv2.line(line_img, pt1i, pt2i, color, int(np.ceil(width / 2)))\n",
    "\n",
    "        # Draw vanishing point as white border, then color\n",
    "        cv2.circle(line_img, vp, 5, (255, 255, 255), -1)\n",
    "        cv2.circle(line_img, vp, 3, color, -1)\n",
    "\n",
    "    if is_manhattan is not None:\n",
    "        legend_patches.append(\n",
    "            Patch(color='gray', label=f\"Is Manhattan = {is_manhattan}\")\n",
    "        )\n",
    "\n",
    "    # Convert BGR to RGB for matplotlib\n",
    "    line_img_rgb = cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(line_img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.legend(handles=legend_patches, loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def save_vanishing_points(\n",
    "    img, linesegments, vanishing_points, labeling,\n",
    "    save_path, name, display_outliers=False, is_manhattan=None\n",
    "):\n",
    "    line_img = img.copy()\n",
    "    model_number = vanishing_points.shape[0]\n",
    "\n",
    "    colours = [\n",
    "        [255, 0, 0], [0, 255, 0], [0, 0, 255], [255, 255, 0],\n",
    "        [0, 255, 255], [255, 0, 255], [128, 0, 0], [0, 128, 0],\n",
    "        [0, 0, 128], [255, 165, 0], [255, 192, 203], [75, 0, 130],\n",
    "        [0, 128, 128], [128, 0, 128],\n",
    "    ]\n",
    "    num_of_colours = len(colours)\n",
    "    width = 3\n",
    "\n",
    "    legend_patches = []\n",
    "\n",
    "    # Draw outliers if requested\n",
    "    if display_outliers:\n",
    "        idx = model_number\n",
    "        indices = [i for i, e in enumerate(labeling) if e == idx]\n",
    "        color = (255, 255, 255)\n",
    "        color_rgb = tuple([c / 255. for c in color[::-1]])\n",
    "        legend_label = f\"Outliers: {len(indices)} lines\"\n",
    "        legend_patches.append(Patch(color=color_rgb, label=legend_label))\n",
    "        for i in indices:\n",
    "            pt1 = tuple(map(int, linesegments[i, 0:2]))\n",
    "            pt2 = tuple(map(int, linesegments[i, 2:4]))\n",
    "            cv2.line(line_img, pt1, pt2, color, int(np.ceil(width / 2)))\n",
    "\n",
    "    # Draw vanishing point lines and add legend\n",
    "    for idx in range(model_number):\n",
    "        indices = [i for i, e in enumerate(labeling) if e == idx]\n",
    "        if idx < num_of_colours:\n",
    "            color = colours[idx]\n",
    "        else:\n",
    "            color = (randint(0, 255), randint(0, 255), randint(0, 255))\n",
    "        color_tuple = tuple(int(c) for c in color)\n",
    "        color_rgb = tuple([c / 255. for c in color[::-1]])\n",
    "        legend_label = f\"VP {idx}: {tuple(map(int, vanishing_points[idx]))}\"\n",
    "        legend_patches.append(Patch(color=color_rgb, label=legend_label))\n",
    "\n",
    "        vp = tuple(map(int, vanishing_points[idx]))\n",
    "        for i in indices:\n",
    "            pt1 = tuple(map(int, linesegments[i, 0:2]))\n",
    "            pt2 = tuple(map(int, linesegments[i, 2:4]))\n",
    "            cv2.line(line_img, pt1, pt2, color_tuple, int(np.ceil(width / 2)))\n",
    "        # Draw vanishing point: white border then colored center\n",
    "        cv2.circle(line_img, vp, 5, (255, 255, 255), -1)\n",
    "        cv2.circle(line_img, vp, 3, color_tuple, -1)\n",
    "\n",
    "    if is_manhattan is not None:\n",
    "        legend_patches.append(\n",
    "            Patch(color='gray', label=f\"Is Manhattan = {is_manhattan}\")\n",
    "        )\n",
    "\n",
    "    # Convert BGR to RGB for Matplotlib\n",
    "    line_img_rgb = cv2.cvtColor(line_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot and save with legend\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(line_img_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.legend(handles=legend_patches, loc='upper right', fontsize=14, frameon=True)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    full_save_path = os.path.join(save_path, name)\n",
    "    plt.savefig(full_save_path, bbox_inches='tight', pad_inches=0.1, dpi=200)\n",
    "    plt.close()\n"
   ],
   "id": "690c725c1810515a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:09:59.029827Z",
     "start_time": "2025-05-30T19:09:59.025714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_camera_parameters(image, model):\n",
    "\n",
    "    if type(model) == PerspectiveFields:\n",
    "        prediction = model.inference(img_bgr=image)\n",
    "\n",
    "        roll = prediction['pred_roll'].cpu().numpy()\n",
    "        pitch = prediction['pred_pitch'].cpu().numpy()\n",
    "        vfov = prediction['pred_general_vfov'].cpu().numpy()\n",
    "        focal_length = prediction['pred_rel_focal'].cpu().numpy() * image.shape[0]\n",
    "\n",
    "        return roll, pitch, vfov, focal_length, prediction\n",
    "\n",
    "    elif type(model) == GeoCalib:\n",
    "        # load image as tensor in range [0, 1] and in format [C, H, W]\n",
    "        img_tensor = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
    "        image_tensor = img_tensor.to(device)\n",
    "        prediction = model.calibrate(image_tensor)\n",
    "\n",
    "        del image_tensor\n",
    "\n",
    "        roll = prediction['camera'].roll.item()\n",
    "        pitch = prediction['camera'].pitch.item()\n",
    "        vfov = prediction['camera'].vfov.item()\n",
    "        focal_length = prediction['camera'].f[0, 1].item()\n",
    "\n",
    "        return roll, pitch, vfov, focal_length, prediction\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {type(model)}\")"
   ],
   "id": "bdf8dab76fb9972d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:09:59.551768Z",
     "start_time": "2025-05-30T19:09:59.549218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_camera_intrinsics(img, cx, cy, focal_length):\n",
    "    # Generate camera intrinsics\n",
    "    K = np.zeros((3, 3))\n",
    "    K[0, 0] = focal_length\n",
    "    K[1, 1] = focal_length\n",
    "    K[0, 2] = cx * img.shape[1] + img.shape[1] / 2\n",
    "    K[1, 2] = cy * img.shape[0] + img.shape[0] / 2\n",
    "    K[2, 2] = 1.0\n",
    "\n",
    "    return K"
   ],
   "id": "f021159928117b81",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:09:59.935356Z",
     "start_time": "2025-05-30T19:09:59.931385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_vp_to_groundtruth(vp, gt_vp):\n",
    "    # Compare the predicted vanishing points array to the ground truth array using angular distance\n",
    "\n",
    "    angular_matrix = np.zeros((len(gt_vp), len(vp)))\n",
    "    for i, true_vp in enumerate(gt_vp):\n",
    "        for j, pred_vp in enumerate(vp):\n",
    "            dist = np.arccos(np.dot(true_vp, pred_vp) / (np.linalg.norm(true_vp) * np.linalg.norm(pred_vp)))\n",
    "            angular_matrix[i, j] = dist\n",
    "\n",
    "    # For each true vp, find the closest predicted vp by angular distance\n",
    "    best_matches = np.min(angular_matrix, axis=1)\n",
    "    best_matches = np.degrees(best_matches)\n",
    "    return best_matches"
   ],
   "id": "47d3cd0cc9315ecc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:10:00.454593Z",
     "start_time": "2025-05-30T19:10:00.449776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_dataset_items(dataset, idx):\n",
    "    sample = dataset[idx] # get a single sample from the dataset\n",
    "    vp_gt_hom = sample['VPs'] # array Mx3 with vanishing points in homogeneous coordinates\n",
    "    image = sample['image'] # RGB image\n",
    "    lines = sample['line_segments'] # array Nx12 containing all extracted line segments\n",
    "    p1 = lines[:, 0:3] # line segment start points in hom. coordinates\n",
    "    p2 = lines[:, 3:6] # line segment end points in hom. coordinates\n",
    "    hom_lines = lines[:, 6:9] # parametrised line [a,b,c] s.t. ax+by+c=0\n",
    "    centroids = lines[:, 9:12] # centroid = (p1+p2)/2.\n",
    "\n",
    "    vp0 = vp_gt_hom[0]\n",
    "    vp1 = vp_gt_hom[1]\n",
    "    vp2 = vp_gt_hom[2]\n",
    "\n",
    "    vp0 = vp0 / vp0[2]\n",
    "    vp1 = vp1 / vp1[2]\n",
    "    vp2 = vp2 / vp2[2]\n",
    "\n",
    "    vp0 = (int(vp0[0]), int(vp0[1]))\n",
    "    vp1 = (int(vp1[0]), int(vp1[1]))\n",
    "    vp2 = (int(vp2[0]), int(vp2[1]))\n",
    "\n",
    "    vp_gt = [vp0, vp1, vp2]\n",
    "\n",
    "    return image, sample, vp_gt"
   ],
   "id": "402e60d65e7fa6d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:10:00.957876Z",
     "start_time": "2025-05-30T19:10:00.954716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def is_manhattan_triple(vps, K, threshold=0.15) -> (bool, float, float, float):\n",
    "    \"\"\"\n",
    "    Returns True if the three vanishing points form a Manhattan frame.\n",
    "    vanishing_points: list of three [x, y] vanishing points\n",
    "    K: camera intrinsic matrix (3x3)\n",
    "    threshold: maximum allowed absolute dot product (cosine of angle) for orthogonality\n",
    "    \"\"\"\n",
    "\n",
    "    if len(vps) < 3:\n",
    "        # Not enough vanishing points\n",
    "        return False, np.nan, np.nan, np.nan\n",
    "\n",
    "    if vps.shape[1] == 2:\n",
    "        vps = np.c_[vps, np.ones(3)]\n",
    "\n",
    "    K_inv = np.linalg.inv(K)\n",
    "    dirs = (K_inv @ vps.T).T          # shape (3,3)\n",
    "    dirs /= np.linalg.norm(dirs, axis=1, keepdims=True)\n",
    "\n",
    "    dot12 = np.dot(dirs[0], dirs[1])\n",
    "    dot23 = np.dot(dirs[1], dirs[2])\n",
    "    dot31 = np.dot(dirs[2], dirs[0])\n",
    "    dots  = np.array([dot12, dot23, dot31])\n",
    "\n",
    "    ok = np.all(np.abs(dots) < threshold)\n",
    "    return ok, dot12, dot23, dot31"
   ],
   "id": "277aca11fa06a6f3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:10:01.353635Z",
     "start_time": "2025-05-30T19:10:01.350230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_segments_by_label(linesegments, labels, L):\n",
    "    \"\"\"\n",
    "    Extract all line segments of label L.\n",
    "\n",
    "    Parameters:\n",
    "        linesegments: numpy array of shape (N, 5)\n",
    "        labels: array-like of shape (N,)\n",
    "        L: label value to extract\n",
    "\n",
    "    Returns:\n",
    "        segments_with_label_L: numpy array of shape (M, 5) for label L\n",
    "        indices: numpy array of shape (M,) for the indices of the segments with label L\n",
    "    \"\"\"\n",
    "    linesegments = np.asarray(linesegments)\n",
    "    labels = np.asarray(labels)\n",
    "    mask = (labels == L)\n",
    "    indices = np.where(mask)[0]\n",
    "    return linesegments[mask], indices\n",
    "\n",
    "\n",
    "def label_map_to_label_array(segments, segment_to_label, missing_value=-1):\n",
    "    \"\"\"\n",
    "    Converts the segment_to_label map to a label array.\n",
    "\n",
    "    Args:\n",
    "        segments (list): List of segment tuples [(x1, y1, x2, y2), ...].\n",
    "        segment_to_label (dict): Map from segment tuple to label (int).\n",
    "        missing_value (int): Value to use if a segment is not found in the map.\n",
    "\n",
    "    Returns:\n",
    "        list: List of labels corresponding to each segment.\n",
    "    \"\"\"\n",
    "    return [\n",
    "        segment_to_label.get(tuple(int(x) for x in seg), missing_value)\n",
    "        for seg in segments\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def update_label_map(segment_to_label, segments_to_update, labels_to_update):\n",
    "    \"\"\"\n",
    "    Update the label map with new labels for a set of segments.\n",
    "\n",
    "    Parameters:\n",
    "        segment_to_label: dictionary mapping segment index to label\n",
    "        segments_to_update: numpy array of shape (M,) with the subset of segments to update\n",
    "        labels_to_update: numpy array of shape (M,) with the new labels for the subset of segments\n",
    "    \"\"\"\n",
    "    for i, label in enumerate(labels_to_update):\n",
    "        segment = segments_to_update[i]\n",
    "        segment_tuple = tuple(np.asarray(segment, dtype=int)) # Convert numpy array to tuple for hashing\n",
    "        segment_to_label[segment_tuple] = label\n",
    "    return segment_to_label"
   ],
   "id": "9a8679250ae3adfc",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:10:02.366125Z",
     "start_time": "2025-05-30T19:10:02.341990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pipeline(image, K, line_detector='both', vp_threshold=2.0, refinement_threshold=1.0, manhattan_threshold=0.15, do_refinement=True, verbose=False, refinement_stragegy='default'):\n",
    "    \"\"\"\n",
    "    Main pipeline function to process an image and extract vanishing points.\n",
    "\n",
    "    Parameters:\n",
    "        image: input image\n",
    "        K: camera intrinsic matrix (3x3)\n",
    "        line_detector: 'lsd+deeplsd', 'lsd+deeplsd-wireframe', 'deeplsd', 'deeplsd-wireframe', or 'lsd'\n",
    "        vp_threshold: threshold for vanishing point detection\n",
    "        refinement_threshold: threshold for refinement step\n",
    "        manhattan_threshold: threshold for Manhattan frame check\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    show_detected_lines = False\n",
    "    if verbose:\n",
    "        show_detected_lines = True\n",
    "\n",
    "    if line_detector == 'lsd+deeplsd':\n",
    "        deeplsd_line_segments = get_line_segments_deepLSD(image, model='default', show_detected_lines=show_detected_lines)\n",
    "        lsd_line_segments = get_line_segments_LSD(image, show_detected_lines=show_detected_lines)\n",
    "        line_segments = np.concatenate((deeplsd_line_segments, lsd_line_segments), axis=0)\n",
    "    elif line_detector == 'lsd+deeplsd-wireframe':\n",
    "        deeplsd_line_segments = get_line_segments_deepLSD(image, model='wireframe', show_detected_lines=show_detected_lines)\n",
    "        lsd_line_segments = get_line_segments_LSD(image, show_detected_lines=show_detected_lines)\n",
    "        line_segments = np.concatenate((deeplsd_line_segments, lsd_line_segments), axis=0)\n",
    "    elif line_detector == 'deeplsd':\n",
    "        line_segments = get_line_segments_deepLSD(image, model='default', show_detected_lines=show_detected_lines)\n",
    "    elif line_detector == 'deeplsd-wireframe':\n",
    "        line_segments = get_line_segments_deepLSD(image, model='wireframe', show_detected_lines=show_detected_lines)\n",
    "    elif line_detector == 'lsd':\n",
    "        line_segments = get_line_segments_LSD(image, show_detected_lines=show_detected_lines)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid line detector. Use 'lsd+deeplsd', 'lsd+deeplsd-wireframe', 'deeplsd', 'deeplsd-wireframe', or 'lsd'.\")\n",
    "\n",
    "    if line_segments.shape[0] < 6:\n",
    "        print(f\"⚠️ Warning: Reverted to LSD because {line_detector} could not find enough line segments.\")\n",
    "        line_segments = get_line_segments_LSD(image, show_detected_lines=show_detected_lines)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Detected {line_segments.shape[0]} line segments.\")\n",
    "\n",
    "    # Get initial vanishing points\n",
    "    initial_vanishing_points, initial_labeling = get_vanishing_points(image, line_segments, threshold=vp_threshold,\n",
    "                                                      minimum_point_number=2, maximum_model_number=3)\n",
    "\n",
    "    # Creates a hash map from segment to label to make it easier to update the labels\n",
    "    segment_to_label = {}\n",
    "    for segment, label in zip(line_segments, initial_labeling):\n",
    "        segment_tuple = tuple(int(x) for x in segment)\n",
    "        segment_to_label[segment_tuple] = label\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Initial vanishing points ({initial_vanishing_points.shape[0]}): \\n {initial_vanishing_points}\")\n",
    "        print(\"Type of initial_vanishing_points: \", type(initial_vanishing_points))\n",
    "        print(\"Shape of initial_vanishing_points: \", initial_vanishing_points.shape)\n",
    "        print(\"Type of line_segments: \", type(line_segments))\n",
    "        print(\"Shape of line_segments: \", line_segments.shape)\n",
    "        labels = label_map_to_label_array(line_segments, segment_to_label)\n",
    "        display_vanishing_points(image, line_segments, initial_vanishing_points, labels, display_outliers=True)\n",
    "\n",
    "    # Check if the initial vanishing points form a Manhattan frame\n",
    "    is_manhattan, dot01, dot12, dot20 = is_manhattan_triple(initial_vanishing_points, K, threshold=manhattan_threshold)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Is inital VP a Manhattan frame: {is_manhattan}\")\n",
    "        print(f\"Inital VP Dot products (dot01, dot12, dot20): {dot01}, {dot12}, {dot20}\")\n",
    "\n",
    "    # If not a Manhattan frame, refine the vanishing points\n",
    "    if not is_manhattan and do_refinement:\n",
    "        if not is_manhattan and np.any(np.isnan([dot01, dot12, dot20])):\n",
    "            # No Manhattan frame detected. Refinement not possible\n",
    "            if verbose: print(\"No Manhattan frame detected. Refinement not possible.\")\n",
    "            return False, initial_vanishing_points, label_map_to_label_array(line_segments, segment_to_label), line_segments, (dot01, dot12, dot20)\n",
    "\n",
    "        if abs(dot01) >= 0.5:\n",
    "            label_A = 0\n",
    "            label_B = 1\n",
    "            label_fixed = 2\n",
    "            dot = dot01\n",
    "            if verbose: print(\"dot01 >= 0.5\")\n",
    "        elif abs(dot12) >= 0.5:\n",
    "            label_fixed = 0\n",
    "            label_A = 1\n",
    "            label_B = 2\n",
    "            dot = dot12\n",
    "            if verbose: print(\"dot12 >= 0.5\")\n",
    "        elif abs(dot20) >= 0.5:\n",
    "            label_A = 2\n",
    "            label_fixed = 1\n",
    "            label_B = 0\n",
    "            dot = dot20\n",
    "            if verbose: print(\"dot20 >= 0.5\")\n",
    "        else:\n",
    "            # No Manhattan frame detected. Refinement not possible\n",
    "            if verbose: print(\"No Manhattan frame detected. Refinement not possible.\")\n",
    "            return False, initial_vanishing_points, label_map_to_label_array(line_segments, segment_to_label), line_segments, (dot01, dot12, dot20)\n",
    "\n",
    "        first_vp = initial_vanishing_points[label_fixed]\n",
    "\n",
    "        # Adjusted the labeling to take into account the refinement\n",
    "        improved_labeling = np.zeros_like(initial_labeling)\n",
    "        improved_labeling[initial_labeling == label_fixed] = label_fixed\n",
    "\n",
    "        label_outliers = len(np.unique(initial_labeling)) - 1\n",
    "        segments_A, indices_A = extract_segments_by_label(line_segments, initial_labeling, label_A)\n",
    "        segments_B, indices_B = extract_segments_by_label(line_segments, initial_labeling, label_B)\n",
    "        segments_fixed, indices_fixed = extract_segments_by_label(line_segments, initial_labeling, label_fixed)\n",
    "        segments_outliers, indices_outliers = extract_segments_by_label(line_segments, initial_labeling, label_outliers)\n",
    "        len_A = segments_A.shape[0]\n",
    "        len_B = segments_B.shape[0]\n",
    "        if len_A > len_B:\n",
    "            segments_main = segments_A\n",
    "            segments_error = segments_B\n",
    "            label_main = label_A\n",
    "            label_error = label_B\n",
    "        else:\n",
    "            segments_main = segments_B\n",
    "            segments_error = segments_A\n",
    "            label_main = label_B\n",
    "            label_error = label_A\n",
    "\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Attempting to refine the vanishing point {label_main} and {label_error} (Dot : {dot})\")\n",
    "            print(f\"Main segments: {segments_main.shape}, Error segments: {segments_error.shape}, Outliers segments: {segments_outliers.shape}\")\n",
    "\n",
    "        all_segments = np.concatenate((segments_main, segments_error, segments_outliers), axis=0)\n",
    "        all_indices = np.concatenate((indices_A, indices_B, indices_outliers), axis=0)\n",
    "\n",
    "        if verbose: print(f\" Refinement segments: {all_segments.shape}\")\n",
    "\n",
    "        improved_second_vp, improved_second_vp_labeling = get_vanishing_points(image, all_segments, threshold=refinement_threshold,\n",
    "                                                          minimum_point_number=2, maximum_model_number=1)\n",
    "\n",
    "        # Adjust the labels\n",
    "        improved_second_vp_label = label_main\n",
    "        for i in range(len(improved_second_vp_labeling)):\n",
    "            if improved_second_vp_labeling[i] == 0:\n",
    "                improved_second_vp_labeling[i] = improved_second_vp_label\n",
    "            else:\n",
    "                improved_second_vp_labeling[i] = label_outliers\n",
    "\n",
    "        segment_to_label = update_label_map(segment_to_label, all_segments, improved_second_vp_labeling)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Displaying the refined 2nd vanishing points\")\n",
    "            print(\"Shape of improved_second_vp: \", improved_second_vp.shape)\n",
    "\n",
    "            temp_labeling = np.zeros_like(improved_second_vp_labeling)\n",
    "            for i, label in enumerate(improved_second_vp_labeling):\n",
    "                if label != label_main:\n",
    "                    temp_labeling[i] = 1\n",
    "\n",
    "            display_vanishing_points(image, all_segments, improved_second_vp, temp_labeling, display_outliers=True)\n",
    "\n",
    "        improved_second_vp = improved_second_vp[0]\n",
    "        if verbose: print(f\"Improved second vanishing point ({improved_second_vp_labeling.shape[0]} labels): \\n {improved_second_vp}\")\n",
    "\n",
    "        \"\"\"\n",
    "        for i in range(len(all_indices)):\n",
    "            predicted_label = improved_second_vp_labeling[i]\n",
    "            if predicted_label == 0:\n",
    "                adjusted_label = label_A\n",
    "                improved_labeling[all_indices[i]] = adjusted_label\n",
    "        \"\"\"\n",
    "\n",
    "        remaining_segments, remaining_indices = extract_segments_by_label(all_segments, improved_second_vp_labeling, label_outliers)\n",
    "\n",
    "        if verbose: print(f\"Remaining segments: {remaining_segments.shape}\")\n",
    "\n",
    "        if remaining_segments.shape[0] == 0:\n",
    "            # No remaining segments to process\n",
    "            if verbose: print(\"No remaining segments to process.\")\n",
    "            return False, initial_vanishing_points, label_map_to_label_array(line_segments, segment_to_label), line_segments, (dot01, dot12, dot20)\n",
    "\n",
    "        if refinement_stragegy == 'default':\n",
    "            third_vp, vps_labeling = get_vanishing_points(image, remaining_segments, threshold=refinement_threshold,\n",
    "                                                          minimum_point_number=2, maximum_model_number=1)\n",
    "\n",
    "            third_vp = third_vp[0]\n",
    "            third_vp = np.expand_dims(third_vp, axis=0)\n",
    "\n",
    "            # Adjust the labeling (0 is vp, rest is outliers)\n",
    "            third_vp_labeling = np.zeros_like(vps_labeling)\n",
    "            third_vp_label = label_error\n",
    "            for i in range(len(vps_labeling)):\n",
    "                if vps_labeling[i] == 0:\n",
    "                    third_vp_labeling[i] = third_vp_label\n",
    "                else:\n",
    "                    third_vp_labeling[i] = label_outliers\n",
    "\n",
    "        elif refinement_stragegy == 'search_optimal':\n",
    "            vps, vps_labeling = get_vanishing_points(image, remaining_segments, threshold=refinement_threshold,\n",
    "                                                          minimum_point_number=2, maximum_model_number=-1)\n",
    "            costs = []\n",
    "            for (label, third_vp) in enumerate(vps):\n",
    "                frame = np.array([first_vp, improved_second_vp, third_vp])\n",
    "                is_manhattan, dot01, dot12, dot20 = is_manhattan_triple(frame, K, threshold=manhattan_threshold)\n",
    "                dots = (dot01, dot12, dot20)\n",
    "                improved_dot = abs(dots[label_error])\n",
    "                # Cost is the norm of dots\n",
    "                cost = np.linalg.norm(dots)\n",
    "                costs.append((third_vp, label, cost))\n",
    "                if verbose: print(f\"Cost of {label}: {cost}\")\n",
    "\n",
    "            if verbose:\n",
    "                    display_vanishing_points(image, remaining_segments, vps, vps_labeling, display_outliers=True)\n",
    "\n",
    "\n",
    "            costs = sorted(costs, key=lambda x: x[2])\n",
    "            third_vp = costs[0][0]\n",
    "            vp_label = costs[0][1]\n",
    "\n",
    "            third_vp = np.expand_dims(third_vp, axis=0)\n",
    "\n",
    "            third_vp_labeling = np.zeros_like(vps_labeling)\n",
    "            third_vp_label = label_error\n",
    "            for i in range(len(vps_labeling)):\n",
    "                if vps_labeling[i] == vp_label:\n",
    "                    third_vp_labeling[i] = third_vp_label\n",
    "                else:\n",
    "                    third_vp_labeling[i] = label_outliers\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Refined third vanishing point ({third_vp_labeling.shape[0]} labels): \\n {third_vp}\")\n",
    "                print(f\"Costs: {costs}\")\n",
    "                print(f\"Best cost: {costs[0]}\")\n",
    "                print(\"Third label = \", third_vp_label)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid strategy selected. Use 'default' or 'search_optimal'\")\n",
    "\n",
    "        segment_to_label = update_label_map(segment_to_label, remaining_segments, third_vp_labeling)\n",
    "        if verbose:\n",
    "            print(\"Displaying the refined 3rd vanishing points\")\n",
    "\n",
    "            # Replace all non-zero labels 1\n",
    "            temp_labeling = np.zeros_like(third_vp_labeling)\n",
    "            for i, label in enumerate(third_vp_labeling):\n",
    "                if label != label_error:\n",
    "                    temp_labeling[i] = 1\n",
    "\n",
    "            print(f\"Uniques: {np.unique(temp_labeling)}\")\n",
    "            display_vanishing_points(image, remaining_segments, third_vp, temp_labeling, display_outliers=True)\n",
    "\n",
    "        \"\"\"\n",
    "        for i in range(len(remaining_indices)):\n",
    "            predicted_label = third_vp_labeling[i]\n",
    "            if predicted_label == third_vp_label:\n",
    "                adjusted_label = label_B\n",
    "                index_in_all_indices = remaining_indices[i]\n",
    "                improved_labeling[all_indices[index_in_all_indices]] = adjusted_label\n",
    "            else:\n",
    "                adjusted_label = label_rest\n",
    "                index_in_all_indices = remaining_indices[i]\n",
    "                improved_labeling[all_indices[index_in_all_indices]] = adjusted_label\n",
    "        \"\"\"\n",
    "\n",
    "        # Update the improved vanishing points\n",
    "        improved_vanishing_points = initial_vanishing_points.copy()\n",
    "        improved_vanishing_points[label_main] = improved_second_vp\n",
    "        improved_vanishing_points[label_error] = third_vp\n",
    "\n",
    "        # Check if the improved vanishing points form a Manhattan frame\n",
    "        is_manhattan, dot01, dot12, dot20 = is_manhattan_triple(improved_vanishing_points, K, threshold=manhattan_threshold)\n",
    "\n",
    "        # Debug print\n",
    "        if verbose:\n",
    "            print(f\"Improved vanishing points: {improved_vanishing_points}\")\n",
    "            print(f\"Is improved VP a Manhattan frame: {is_manhattan}\")\n",
    "            print(f\"Improved VP Dot products (dot01, dot12, dot20): {dot01}, {dot12}, {dot20}\")\n",
    "\n",
    "        return is_manhattan, improved_vanishing_points, label_map_to_label_array(line_segments, segment_to_label), line_segments, (dot01, dot12, dot20)\n",
    "\n",
    "    # Initial vanishing points already form a Manhattan frame\n",
    "    return is_manhattan, initial_vanishing_points, label_map_to_label_array(line_segments, segment_to_label), line_segments, (dot01, dot12, dot20)"
   ],
   "id": "cd40f643135ec984",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:10:03.211838Z",
     "start_time": "2025-05-30T19:10:03.208745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def resize_preserve_aspect(image, max_width=640, max_height=480):\n",
    "    h, w = image.shape[:2]\n",
    "    scale = min(max_width / w, max_height / h)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(image, (new_w, new_h))\n",
    "    return resized"
   ],
   "id": "c9884064357fa0d5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T19:10:06.476107Z",
     "start_time": "2025-05-30T19:10:06.473770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_file_paths(folder):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder)\n",
    "            if os.path.isfile(os.path.join(folder, f))]"
   ],
   "id": "1998374e4c254974",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T18:05:09.894538Z",
     "start_time": "2025-05-30T18:05:08.687287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ext.GeoCalib.geocalib.extractor import GeoCalib\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "geocalib_model = GeoCalib(weights='pinhole').to(device)"
   ],
   "id": "98cb81864e7460c8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T18:05:09.908161Z",
     "start_time": "2025-05-30T18:05:09.904033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = YUDVP(\"./data\", split='all', normalize_coords=False, return_images=True, extract_lines=False, yudplus=False)\n",
    "\n",
    "K_groundtruth = np.array([\n",
    "    [674.91797516, 0., 307.55130528],\n",
    "    [0., 674.91797516, 251.45424496],\n",
    "    [0., 0., 1.]\n",
    "])"
   ],
   "id": "d421c335c1059c1b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:01:24.273441Z",
     "start_time": "2025-05-30T09:56:49.774374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = \"data/plots/real\"\n",
    "\n",
    "results_real = []\n",
    "\n",
    "start_overall = time.time()\n",
    "\n",
    "total = len(dataset)\n",
    "true_count = 0\n",
    "\n",
    "for idx in range(total):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    image, _, _ = extract_dataset_items(dataset, idx)\n",
    "    filename = \"york_\" + str(idx) + \".png\"\n",
    "\n",
    "    cpy = image.copy()\n",
    "\n",
    "    img_tensor = torch.tensor(cpy).permute(2, 0, 1) / 255.0\n",
    "    image_tensor = img_tensor.to(device)\n",
    "    geolib_result = geocalib_model.calibrate(image_tensor)\n",
    "\n",
    "    focal_geolib = geolib_result['camera'].f[0, 1].item()\n",
    "\n",
    "\n",
    "    K_geolib = generate_camera_intrinsics(image, 0, 0, focal_geolib)\n",
    "    is_manhattan, vps, labeling, line_segments, (dot01, dot12, dot20) = pipeline(image, K_geolib,\n",
    "                                                                                 line_detector='deeplsd',\n",
    "                                                                                 vp_threshold=1.0,\n",
    "                                                                                 refinement_threshold=0.75,\n",
    "                                                                                 manhattan_threshold=0.15,\n",
    "                                                                                 do_refinement=True, verbose=False,\n",
    "                                                                                 refinement_stragegy='search_optimal')\n",
    "\n",
    "    iter_time = time.time() - iter_start\n",
    "    total_elapsed = time.time() - start_overall\n",
    "    avg_time = total_elapsed / (idx + 1)\n",
    "    remaining_time = avg_time * (total - idx - 1)\n",
    "\n",
    "    if is_manhattan:\n",
    "        true_count += 1\n",
    "\n",
    "    print(\n",
    "        f\"True: {true_count} / {total}, Index: {idx + 1}/{total}, Time: {iter_time:.3f}s, Est. Remaining: {remaining_time:.1f}s\",\n",
    "        end='\\r'\n",
    "    )\n",
    "\n",
    "    results_real.append((is_manhattan, (dot01, dot12, dot20), filename))\n",
    "\n",
    "    save_vanishing_points(image, line_segments, vps, labeling, save_path, filename, display_outliers=True,\n",
    "                          is_manhattan=is_manhattan)\n",
    "\n",
    "    del image_tensor\n",
    "    del image\n",
    "    del geolib_result\n",
    "    del vps\n",
    "    del labeling\n",
    "    del line_segments\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ],
   "id": "6938e4890062c444",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 79 / 102, Index: 102/102, Time: 2.102s, Est. Remaining: 0.0s\r"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:07:56.484318Z",
     "start_time": "2025-05-30T10:03:33.979197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "save_path = \"data/plots/real_K_groundtruth\"\n",
    "\n",
    "results_real_K_groundtruth = []\n",
    "\n",
    "start_overall = time.time()\n",
    "\n",
    "total = len(dataset)\n",
    "true_count = 0\n",
    "\n",
    "for idx in range(total):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    image, _, _ = extract_dataset_items(dataset, idx)\n",
    "    filename = \"york_\" + str(idx) + \".png\"\n",
    "\n",
    "    is_manhattan, vps, labeling, line_segments, (dot01, dot12, dot20) = pipeline(image, K_groundtruth,\n",
    "                                                                                 line_detector='deeplsd',\n",
    "                                                                                 vp_threshold=1.0,\n",
    "                                                                                 refinement_threshold=0.75,\n",
    "                                                                                 manhattan_threshold=0.15,\n",
    "                                                                                 do_refinement=True, verbose=False,\n",
    "                                                                                 refinement_stragegy='search_optimal')\n",
    "\n",
    "    iter_time = time.time() - iter_start\n",
    "    total_elapsed = time.time() - start_overall\n",
    "    avg_time = total_elapsed / (idx + 1)\n",
    "    remaining_time = avg_time * (total - idx - 1)\n",
    "\n",
    "    if is_manhattan:\n",
    "        true_count += 1\n",
    "\n",
    "    print(\n",
    "        f\"True: {true_count} / {total}, Index: {idx + 1}/{total}, Time: {iter_time:.3f}s, Est. Remaining: {remaining_time:.1f}s\",\n",
    "        end='\\r'\n",
    "    )\n",
    "\n",
    "    results_real_K_groundtruth.append((is_manhattan, (dot01, dot12, dot20), filename))\n",
    "\n",
    "    save_vanishing_points(image, line_segments, vps, labeling, save_path, filename, display_outliers=True,\n",
    "                          is_manhattan=is_manhattan)\n",
    "\n",
    "    del vps\n",
    "    del labeling\n",
    "    del line_segments\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ],
   "id": "c6846fb642faea69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 92 / 102, Index: 102/102, Time: 2.740s, Est. Remaining: 0.0s\r"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T18:53:24.041686Z",
     "start_time": "2025-05-30T18:49:20.929117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_generated = []\n",
    "\n",
    "start_overall = time.time()\n",
    "\n",
    "dataset_path = \"data/synthbuster/keep\"\n",
    "files = get_file_paths(dataset_path)\n",
    "\n",
    "save_path = \"data/plots/generated_resized\"\n",
    "\n",
    "total = len(files)\n",
    "true_count = 0\n",
    "\n",
    "for idx, path in enumerate(files):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = resize_preserve_aspect(image)\n",
    "    filename = os.path.basename(path)\n",
    "\n",
    "    cpy = image.copy()\n",
    "\n",
    "    img_tensor = torch.tensor(cpy).permute(2, 0, 1) / 255.0\n",
    "    image_tensor = img_tensor.to(device)\n",
    "    geolib_result = geocalib_model.calibrate(image_tensor)\n",
    "\n",
    "    focal_geolib = geolib_result['camera'].f[0, 1].item()\n",
    "\n",
    "    K_geolib = generate_camera_intrinsics(image, 0, 0, focal_geolib)\n",
    "    is_manhattan, vps, labeling, line_segments, (dot01, dot12, dot20) = pipeline(image, K_geolib,\n",
    "                                                                                 line_detector='deeplsd',\n",
    "                                                                                 vp_threshold=1.0,\n",
    "                                                                                 refinement_threshold=0.75,\n",
    "                                                                                 manhattan_threshold=0.15,\n",
    "                                                                                 do_refinement=True, verbose=False,\n",
    "                                                                                 refinement_stragegy='search_optimal')\n",
    "\n",
    "    iter_time = time.time() - iter_start\n",
    "    total_elapsed = time.time() - start_overall\n",
    "    avg_time = total_elapsed / (idx + 1)\n",
    "    remaining_time = avg_time * (total - idx - 1)\n",
    "\n",
    "    if is_manhattan:\n",
    "        true_count += 1\n",
    "\n",
    "    print(\n",
    "        f\"True: {true_count} / {total}, Index: {idx + 1}/{total}, Time: {iter_time:.3f}s, Est. Remaining: {remaining_time:.1f}s\",\n",
    "        end='\\r'\n",
    "    )\n",
    "\n",
    "    #\n",
    "    results_generated.append((is_manhattan, (dot01, dot12, dot20), filename))\n",
    "\n",
    "    save_vanishing_points(image, line_segments, vps, labeling, save_path, filename, display_outliers=True, is_manhattan=is_manhattan)\n",
    "\n",
    "    del image_tensor\n",
    "    del image\n",
    "    del geolib_result\n",
    "    del vps\n",
    "    del labeling\n",
    "    del line_segments\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ],
   "id": "e90da0926276a686",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True: 4 / 101, Index: 9/101, Time: 1.929s, Est. Remaining: 216.7s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05/30/2025 20:49:43 geocalib.lm_optimizer WARNING] Reached maximum number of steps without convergence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "⚠️ Warning: Reverted to LSD because deeplsd could not find enough line segments.\n",
      "True: 34 / 101, Index: 101/101, Time: 1.702s, Est. Remaining: 0.0s\r"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T10:21:15.601965Z",
     "start_time": "2025-05-30T10:20:48.590856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "results_focal_uncertainty_real = []\n",
    "\n",
    "start_overall = time.time()\n",
    "\n",
    "total = len(dataset)\n",
    "true_count = 0\n",
    "\n",
    "print(\"Starting Focal Uncertainty evaluation for YUD\")\n",
    "\n",
    "for idx in range(total):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    image, _, _ = extract_dataset_items(dataset, idx)\n",
    "    filename = \"york_\" + str(idx) + \".png\"\n",
    "\n",
    "    cpy = image.copy()\n",
    "\n",
    "    img_tensor = torch.tensor(cpy).permute(2, 0, 1) / 255.0\n",
    "    image_tensor = img_tensor.to(device)\n",
    "    geolib_result = geocalib_model.calibrate(image_tensor)\n",
    "\n",
    "    focal_geolib = geolib_result['camera'].f[0, 1].item()\n",
    "    focal_uncertainty = geolib_result['focal_uncertainty'].item()\n",
    "\n",
    "    results_focal_uncertainty_real.append((focal_uncertainty, filename))\n",
    "\n",
    "    iter_time = time.time() - iter_start\n",
    "    total_elapsed = time.time() - start_overall\n",
    "    avg_time = total_elapsed / (idx + 1)\n",
    "    remaining_time = avg_time * (total - idx - 1)\n",
    "\n",
    "    print(\n",
    "        f\"Index: {idx + 1}/{total}, Time: {iter_time:.3f}s, Est. Remaining: {remaining_time:.1f}s\",\n",
    "        end='\\r'\n",
    "    )\n",
    "\n",
    "print(\"Starting Focal Uncertainty evaluation for Synthbuster\")\n",
    "\n",
    "\n",
    "results_focal_uncertainty_generated = []\n",
    "\n",
    "start_overall = time.time()\n",
    "\n",
    "dataset_path = \"data/synthbuster/keep\"\n",
    "files = get_file_paths(dataset_path)\n",
    "\n",
    "total = len(files)\n",
    "true_count = 0\n",
    "\n",
    "for idx, path in enumerate(files):\n",
    "    iter_start = time.time()\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image = resize_preserve_aspect(image)\n",
    "    filename = os.path.basename(path)\n",
    "\n",
    "    cpy = image.copy()\n",
    "\n",
    "    #\n",
    "\n",
    "    img_tensor = torch.tensor(cpy).permute(2, 0, 1) / 255.0\n",
    "    image_tensor = img_tensor.to(device)\n",
    "    geolib_result = geocalib_model.calibrate(image_tensor)\n",
    "\n",
    "    focal_geolib = geolib_result['camera'].f[0, 1].item()\n",
    "    focal_uncertainty = geolib_result['focal_uncertainty'].item()\n",
    "\n",
    "    results_focal_uncertainty_generated.append((focal_uncertainty, filename))\n",
    "\n",
    "\n",
    "    iter_time = time.time() - iter_start\n",
    "    total_elapsed = time.time() - start_overall\n",
    "    avg_time = total_elapsed / (idx + 1)\n",
    "    remaining_time = avg_time * (total - idx - 1)\n",
    "\n",
    "\n",
    "    print(\n",
    "        f\"Index: {idx + 1}/{total}, Time: {iter_time:.3f}s, Est. Remaining: {remaining_time:.1f}s\",\n",
    "        end='\\r'\n",
    "    )\n",
    "\n",
    "print(\"Finished Evaluation\", end='\\r')\n",
    "\n",
    "focal_uncertainties_real = [x[0] for x in results_focal_uncertainty_real]\n",
    "focal_uncertainties_generated = [x[0] for x in results_focal_uncertainty_generated]\n",
    "\n",
    "mean_uncertainty_real = np.mean(focal_uncertainties_real)\n",
    "std_uncertainty_real = np.std(focal_uncertainties_real)\n",
    "\n",
    "mean_uncertainty_generated = np.mean(focal_uncertainties_generated)\n",
    "std_uncertainty_generated = np.std(focal_uncertainties_generated)\n",
    "\n",
    "print(f\"Real Mean focal uncertainty: {mean_uncertainty_real:.4f}\")\n",
    "print(f\"Real Standard deviation: {std_uncertainty_real:.4f}\")\n",
    "\n",
    "print(f\"Generated Mean focal uncertainty: {mean_uncertainty_generated:.4f}\")\n",
    "print(f\"Generated Standard deviation: {std_uncertainty_generated:.4f}\")"
   ],
   "id": "d06abf1961d9c15c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Focal Uncertainty evaluation for YUD\n",
      "Starting Focal Uncertainty evaluation for Synthbuster\n",
      "Index: 8/101, Time: 0.139s, Est. Remaining: 16.4s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[05/30/2025 12:21:02 geocalib.lm_optimizer WARNING] Reached maximum number of steps without convergence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Mean focal uncertainty: 130.0664maining: 0.0s\n",
      "Real Standard deviation: 79.7434\n",
      "Generated Mean focal uncertainty: 595.4646\n",
      "Generated Standard deviation: 1170.7545\n"
     ]
    }
   ],
   "execution_count": 27
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
